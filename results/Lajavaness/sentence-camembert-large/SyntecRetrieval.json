{
  "dataset_revision": "19661ccdca4dfc2d15122d776b61685f48c68ca9",
  "evaluation_time": 3.039055109024048,
  "kg_co2_emissions": null,
  "mteb_version": "1.11.19",
  "scores": {
    "test": [
      {
        "hf_subset": "default",
        "languages": [
          "fra-Latn"
        ],
        "main_score": 0.79127,
        "map_at_1": 0.62,
        "map_at_10": 0.73944,
        "map_at_100": 0.74245,
        "map_at_1000": 0.74245,
        "map_at_20": 0.74158,
        "map_at_3": 0.72333,
        "map_at_5": 0.73233,
        "mrr_at_1": 0.62,
        "mrr_at_10": 0.73944,
        "mrr_at_100": 0.74245,
        "mrr_at_1000": 0.74245,
        "mrr_at_20": 0.74158,
        "mrr_at_3": 0.72333,
        "mrr_at_5": 0.73233,
        "ndcg_at_1": 0.62,
        "ndcg_at_10": 0.79127,
        "ndcg_at_100": 0.80328,
        "ndcg_at_1000": 0.80328,
        "ndcg_at_20": 0.79891,
        "ndcg_at_3": 0.75833,
        "ndcg_at_5": 0.77468,
        "precision_at_1": 0.62,
        "precision_at_10": 0.095,
        "precision_at_100": 0.01,
        "precision_at_1000": 0.001,
        "precision_at_20": 0.049,
        "precision_at_3": 0.28667,
        "precision_at_5": 0.18,
        "recall_at_1": 0.62,
        "recall_at_10": 0.95,
        "recall_at_100": 1.0,
        "recall_at_1000": 1.0,
        "recall_at_20": 0.98,
        "recall_at_3": 0.86,
        "recall_at_5": 0.9
      }
    ]
  },
  "task_name": "SyntecRetrieval"
}